package com.phdlabs.sungwon.a8chat_android.structure.camera.fragments.normal

import android.graphics.SurfaceTexture
import android.hardware.camera2.*
import android.media.ImageReader
import android.os.Bundle
import android.os.Handler
import android.os.HandlerThread
import android.util.Size
import android.util.SparseIntArray
import android.view.*
import com.phdlabs.sungwon.a8chat_android.R
import com.phdlabs.sungwon.a8chat_android.structure.camera.cameraControl.AutoFitTextureView
import com.phdlabs.sungwon.a8chat_android.structure.camera.fragments.CameraBaseFragment
import kotlinx.android.synthetic.main.fragment_cameranormal.*
import java.io.File
import java.util.*
import java.util.concurrent.Semaphore

/**
 * Created by paix on 12/28/17.
 *
 */
class NormalFragment : CameraBaseFragment(), NormalContract.View {


    /**
     * Controller
     * */
    override lateinit var controller: NormalContract.Controller

    /**
     * Camera Properties
     * */
    /*ID of the current camera device*/
    val cameraId: String? = null
    /*Capture session for camera preview*/
    val mCaptureSession: CameraCaptureSession? = null
    /*Camera device*/
    val mCameraDevice: CameraDevice? = null
    /*Camera peview size*/
    val mPreviewSize: Size? = null

    /**
     * Image Properties
     * */
    /*Additional thread to avoid blocking the UI*/
    val mBackgroundThread: HandlerThread? = null
    /*Handler for running tasks in the background*/
    val mBackgroundHandler: Handler? = null
    /*Image reader that handles still image capturing*/
    val mImageReader: ImageReader? = null
    /*Picture output file*/
    var mFile: File? = null
    /*Capture request builder for the camera preview*/
    var mPreviewRequestBuilder: CaptureRequest.Builder? = null
    /*Capture request generated by [mPreviewCaptureRequestBuilder]*/
    var mPreviewRequest: CaptureRequest? = null
    /*The current state of the camera for taking pictures*/
    var mState: Int = STATE_PREVIEW
    /*Semaphore to prevent the app from exiting before closing the camera*/
    var mCameraOpenCloseLock: Semaphore? = null
    /*Whether the current camera supports flash or not*/
    var mFlashSupported: Boolean? = null
    /*Orientation for the caemra sensor*/
    var mSensorOrientation: Int? = null

    /*LifeCycle*/
    init {
        /*Screen rotation to JPEG rotation*/
        addOrientations()
    }

    override fun onCreate(savedInstanceState: Bundle?) {
        super.onCreate(savedInstanceState)
        /*Init controller*/
        NormalController(this)

    }

    override fun onActivityCreated(savedInstanceState: Bundle?) {
        super.onActivityCreated(savedInstanceState)
        mFile = File(activity?.getExternalFilesDir(null), "pic.jpg")
    }

    override fun onStart() {
        super.onStart()
        controller.start()
    }

    override fun onResume() {
        super.onResume()
        controller.resume()
        //TODO: startBackgroundThread()
        /*When screen is turned on & off -> SurfaceTexture is already available & will not be
        * called. We can open a camera and start preview from [onResume] || we wait until the surface
        * is ready in the surfaceTextureListener*/
        if (mTextureView.isAvailable) {
            //TODO: openCamera(mTextureView.width, mTextureView.height)
        } else {
            mTextureView.surfaceTextureListener = mSurfaceTextureListener
        }
    }

    override fun onPause() {
        super.onPause()
        controller.pause()
        //TODO: closeCamera()
        //TODO: stopBackgroundThread()
    }


    override fun onStop() {
        super.onStop()
        controller.stop()
    }

    override fun cameraLayoutId(): Int = R.layout.fragment_cameranormal

    override fun inOnCreateView(root: View?, container: ViewGroup?, savedInstanceState: Bundle?) {
    }


    /**
     * Companion
     * */
    companion object {

        /*instance*/
        fun create(): NormalFragment = NormalFragment()

        /*Screen Rotation to JPEG conversion*/
        var ORIENTATIONS: SparseIntArray = SparseIntArray()

        fun addOrientations() {
            ORIENTATIONS.append(Surface.ROTATION_0, 90)
            ORIENTATIONS.append(Surface.ROTATION_90, 0)
            ORIENTATIONS.append(Surface.ROTATION_180, 270)
            ORIENTATIONS.append(Surface.ROTATION_270, 180)
        }

        /*Camera permissions*/
        var REQUEST_CAMERA_PERMISSION = 1 //TODO: Change camera permissions -> Constants

        /*Dialog*/
        var FRAGMENT_DIALOG = "dialog"

        /**
         * Camera States
         * */
        private val STATE_PREVIEW: Int = 0 //Showing camera preview
        private val STATE_WAITING_LOCK: Int = 1 // Waiting for the focus to be locked
        private val STATE_WAITING_PRECAPTURE: Int = 2 // Waiting for the exposure to be in pre-capture state
        private val STATE_WAITING_NON_PRECAPTURE: Int = 3 // Waiting for the exposure state to be anything but pre-capture
        private val STATE_PICTURE_TAKEN: Int = 4 // Picture was taken
        private val MAX_PREVIEW_WIDTH = 1920 // Max preview width guaranteed by camera API-2
        private val MAX_PREVIEW_HEIGHT = 1080 // Max preview height guaranteed by camera API -2


        /**
         * [chooseOptimalSize]
         * Resolutions for the available SurfaceView
         * From the given choices supported by the camera, choose the smallest one that is at least as
         * large as the texture view size, and as large as the respective maximum size. If such size
         * doesn't exist, it will choose the largest one that is at most as large as the respective
         * maximum size, and matches with the aspect ratio of the specified value
         * @param choices
         * @param textureViewWidth
         * @param textureViewHeight
         * @param maxWidth
         * @param maxHeight
         * @param aspectRatio
         * @return optimal size or an arbitrary one if none were big enough
         * */
        private fun chooseOptimalSize(choices: ArrayList<Size>, textureViewWidth: Int, textureViewHeight: Int,
                                      maxWidth: Int, maxHeight: Int, aspectRatio: Size): Size? {
            //collect supported resolutions that are at least as big as the preview surface
            val bigEnough: ArrayList<Size> = ArrayList<Size>()
            //collect supported resolutions that are smaller than the preview surface
            val smallEnough: ArrayList<Size> = ArrayList<Size>()
            //Width & Height
            val width: Int = aspectRatio.width
            val height: Int = aspectRatio.height
            choices
                    .filter { it.width <= maxWidth && it.height <= maxHeight && it.height == (it.width * height / width) }
                    .forEach {
                        if (it.width >= textureViewWidth &&
                                it.height >= textureViewHeight) {
                            bigEnough.add(it)
                        } else {
                            smallEnough.add(it)
                        }
                    }
            //Pick the smallest for the smallEnough
            if (bigEnough.size > 0) {
                //TODO: compareSizesByArea()
                //return Collections.min(bigEnough, CompareSizesByArea())
            } else if (smallEnough.size > 0) {
                //TODO: compareSizesByArea()
                //return Collections.max(smallEnough, CompareSizesByArea())
            } else {
                return choices[0]
            }
            return null
        }


    }//end companion

    /**
     * [mSurfaceTextureListener]
     * SurfaceTextureListener for handling lifecycle events on the TextureView
     * @Link TextureView
     * */
    private val mSurfaceTextureListener = object : TextureView.SurfaceTextureListener {
        override fun onSurfaceTextureSizeChanged(p0: SurfaceTexture?, p1: Int, p2: Int) {
            //TODO: configureTransform(width, height)
        }

        override fun onSurfaceTextureUpdated(p0: SurfaceTexture?) {
        }

        override fun onSurfaceTextureDestroyed(p0: SurfaceTexture?): Boolean = true

        override fun onSurfaceTextureAvailable(p0: SurfaceTexture?, p1: Int, p2: Int) {
            //TODO: openCamera(width, height)
        }
    }


    //TODO: Finish implementing Camera Device State Callback
    /**
     * [mStateCallback]
     * Camera state callback changes when the Camera device changes state
     * */
    private val mStateCallback = object : CameraDevice.StateCallback() {

        override fun onOpened(p0: CameraDevice?) {
            TODO("not implemented") //To change body of created functions use File | Settings | File Templates.
        }

        override fun onDisconnected(p0: CameraDevice?) {
            TODO("not implemented") //To change body of created functions use File | Settings | File Templates.
        }

        override fun onError(p0: CameraDevice?, p1: Int) {
            TODO("not implemented") //To change body of created functions use File | Settings | File Templates.
        }

    }

    /**
     * [mOnImageAvailableListener]
     * Callback object for the [ImageReader] which is called when a still image is ready to be saved
     * */
    private val mOnImageAvailableListener = object : ImageReader.OnImageAvailableListener {
        override fun onImageAvailable(p0: ImageReader?) {
            TODO("not implemented") //To change body of created functions use File | Settings | File Templates.
            //TODO: post imageSaver
        }
    }

    /**
     * [CameraCaptureSession.CaptureCallback] handling the events related to the JPEG capture
     * */

    private val mCaptureCallback = object : CameraCaptureSession.CaptureCallback() {

        fun process(captureResult: CaptureResult?) {
            when (mState) {

                STATE_PREVIEW -> {
                    /*Do nothing when camera preview is working*/
                    return
                }

                STATE_WAITING_LOCK -> {
                    /*AutoFocus*/
                    val afState: Int? = captureResult?.get(CaptureResult.CONTROL_AF_STATE)
                    afState?.let {
                        if (it == (CaptureResult.CONTROL_AF_STATE_FOCUSED_LOCKED) ||
                                it == (CaptureResult.CONTROL_AF_STATE_NOT_FOCUSED_LOCKED)) {
                            /*AutoExposure -> Can be null on some devices*/
                            val aeState: Int? = captureResult.get(CaptureResult.CONTROL_AE_STATE)
                            if (aeState == null || aeState == CaptureResult.CONTROL_AE_STATE_CONVERGED) {
                                mState = STATE_PICTURE_TAKEN
                                //TODO: captureStillPicture()
                            } else {
                                //TODO: runPrecaptureSequence()
                            }
                        }
                    } ?: run {
                        //TODO: captureStillPicture()
                    }
                    return
                }

                STATE_WAITING_PRECAPTURE -> {
                    /*AutoFocus -> can be null on some devices*/
                    val aeState: Int? = captureResult?.get(CaptureResult.CONTROL_AE_STATE)
                    if (aeState == null ||
                            aeState == CaptureResult.CONTROL_AE_STATE_PRECAPTURE ||
                            aeState == CaptureRequest.CONTROL_AE_STATE_FLASH_REQUIRED) {
                        mState = STATE_WAITING_NON_PRECAPTURE
                    }
                    return
                }

                STATE_WAITING_NON_PRECAPTURE -> {
                    /*AutoFocus -> can be null on some devices*/
                    val aeState: Int? = captureResult?.get(CaptureResult.CONTROL_AE_STATE)
                    if (aeState == null ||
                            aeState != CaptureResult.CONTROL_AE_STATE_PRECAPTURE) {
                        mState = STATE_PICTURE_TAKEN
                        //TODO: captureStillPicture()
                    }
                    return
                }

            }
        }

        /*required*/
        override fun onCaptureProgressed(session: CameraCaptureSession?, request: CaptureRequest?, partialResult: CaptureResult?) {
            process(partialResult)
        }

        /*required*/
        override fun onCaptureCompleted(session: CameraCaptureSession?, request: CaptureRequest?, result: TotalCaptureResult?) {
            process(result)
        }

    }

    /*Camera permissions*/
    private fun requestCameraPermissions() {
        //TODO: Finish camera permissions
    }


}
